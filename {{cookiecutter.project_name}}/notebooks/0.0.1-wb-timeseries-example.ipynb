{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Series Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIONAL: Load the \"autoreload\" extension so that code can change\n",
    "%load_ext autoreload\n",
    "\n",
    "# OPTIONAL: always reload modules so that as you change code in src, it gets loaded\n",
    "%autoreload 2\n",
    "\n",
    "from src.data import make_dataset\n",
    "from pathlib import Path\n",
    "\n",
    "# path to the root of the repo\n",
    "project_dir = Path().resolve().parents[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data\n",
    "\n",
    "Lets import the data, dont do anything with it, just look at it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the data\n",
    "df = pd.read_csv(project_dir / 'data' / 'raw' / 'jena_climate_2009_2016.csv')\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrangling\n",
    "\n",
    "Now let's dive a little deeper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Date Time (object) to datetime (datetime64)\n",
    "df['datetime'] = pd.to_datetime(df['Date Time'], format='%d.%m.%Y %H:%M:%S')\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check date range\n",
    "\n",
    "It looks like the date time column has a 10 minute interval, lets check this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_range = pd.date_range(\n",
    "    start=df['datetime'].min(),\n",
    "    end=df['datetime'].max(),\n",
    "    freq='10min'\n",
    ")\n",
    "\n",
    "if df.shape[0] != date_range.shape[0]:\n",
    "    print(f\"the dataframe ({df.shape[0]}) and date_range ({date_range.shape[0]}) do NOT have the same length.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "even if the dataframe has the same length as the date_range, there could still be something wrong:\n",
    "- if the number of duplicates matches the number of missing\n",
    "- if the number of duplicates fills the missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handle duplicate values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the duplicate 'datetime' entries\n",
    "df[df['datetime'].duplicated(keep=False)].sort_values(by='datetime')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So there are 327 rows with duplicate (or more) datetimes, let's drop the duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the duplicates\n",
    "df = df.drop_duplicates(keep='first')\n",
    "\n",
    "print(f\"df.shape == {df.shape}\")\n",
    "\n",
    "# sanity check (there should be 0 duplicates now)\n",
    "df[df['datetime'].duplicated(keep=False)].sort_values(by='datetime')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handle index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the index\n",
    "ts = df.set_index('datetime')\n",
    "\n",
    "# show the new index\n",
    "ts.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fact that `freq = None` means that there is no complete frequency, so there are values missing (we've already removed the duplicates). Lets fix the missing.\n",
    "\n",
    "### Handle missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the \"old\" date time column\n",
    "ts = ts.drop(columns=\"Date Time\")\n",
    "\n",
    "# resample (fill missing values)\n",
    "ts = ts.resample('10min').ffill()\n",
    "\n",
    "# sanity check (check if the index is correct)\n",
    "ts.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity check (there should be 0 records with missing values)\n",
    "ts[ts.isna().any(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice, now the start & end date matches as well as the frequency. \n",
    "\n",
    "### Visualise the temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using graph_objects\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "go.Figure([go.Scatter(\n",
    "    x=ts.index, \n",
    "    y=ts['T (degC)'])]\n",
    ").update_layout(\n",
    "    title='Timeseries', \n",
    "    xaxis_title=\"Date time\",\n",
    "    yaxis_title=\"T (degC)\",\n",
    ").update_xaxes(\n",
    "    rangeslider_visible=True,\n",
    "    rangeselector=dict(\n",
    "        buttons=list([\n",
    "            dict(count=1, label=\"1d\", step=\"day\", stepmode=\"backward\"),\n",
    "            dict(count=7, label=\"1w\", step=\"day\", stepmode=\"backward\"),\n",
    "            dict(count=1, label=\"1m\", step=\"month\", stepmode=\"backward\"),\n",
    "            dict(count=1, label=\"1y\", step=\"year\", stepmode=\"backward\"),\n",
    "            dict(step=\"all\")\n",
    "        ])\n",
    "    )\n",
    ").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decompose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "# import plotly.io as pio\n",
    "from statsmodels.tsa.seasonal import DecomposeResult\n",
    "\n",
    "def plot_seasonal_decompose(result:DecomposeResult, dates:pd.Series=None, title:str=\"Seasonal Decomposition\"):\n",
    "    # pio.templates.default = \"plotly_white\"\n",
    "\n",
    "    x_values = dates if dates is not None else np.arange(len(result.observed))\n",
    "    fig = (\n",
    "        make_subplots(\n",
    "            rows=4,\n",
    "            cols=1,\n",
    "            shared_xaxes=True,\n",
    "            vertical_spacing=0.025\n",
    "        )\n",
    "        .add_trace(\n",
    "            go.Scatter(x=x_values, y=result.observed, mode=\"lines\", name='Observed'),\n",
    "            row=1,\n",
    "            col=1,\n",
    "        )\n",
    "        .add_trace(\n",
    "            go.Scatter(x=x_values, y=result.trend, mode=\"lines\", name='Trend'),\n",
    "            row=2,\n",
    "            col=1,\n",
    "        )\n",
    "        .add_trace(\n",
    "            go.Scatter(x=x_values, y=result.seasonal, mode=\"lines\", name='Seasonal'),\n",
    "            row=3,\n",
    "            col=1,\n",
    "        )\n",
    "        .add_trace(\n",
    "            go.Scatter(x=x_values, y=result.resid, mode=\"lines\", name='Residual'),\n",
    "            row=4,\n",
    "            col=1,\n",
    "        )\n",
    "        .update_layout(\n",
    "            height=600, \n",
    "            title=title, \n",
    "            showlegend=False\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # edit axis labels\n",
    "    fig['layout']['yaxis']['title']='Observed'\n",
    "    fig['layout']['yaxis2']['title']='Trend'\n",
    "    fig['layout']['yaxis3']['title']='Seasonal'\n",
    "    fig['layout']['yaxis4']['title']='Residuals'\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "# statsmodels cant handle the 10 minute '10T' frequency from pandas so we need set manually the period (1 year)\n",
    "period = int((365*24*60)/10)\n",
    "\n",
    "# decompose\n",
    "decomposition = sm.tsa.seasonal_decompose(\n",
    "    x=ts['T (degC)'],\n",
    "    period=period\n",
    ")\n",
    "\n",
    "# show decomposition\n",
    "fig = plot_seasonal_decompose(decomposition, dates=ts.index)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
